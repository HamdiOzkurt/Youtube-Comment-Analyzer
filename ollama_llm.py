"""
Ollama LLM Wrapper - Local AI Model Support
Gemini yerine local Ollama kullanÄ±mÄ± iÃ§in
"""

import requests
from typing import List, Optional
from dataclasses import dataclass


@dataclass
class OllamaSummaryResult:
    """Ollama Ã¶zet sonucu"""
    summary: str
    raw_response: str


class OllamaLLM:
    """Local Ollama ile yorum Ã¶zetleme"""
    
    def __init__(self, model_name: str = "gemma3:4b", base_url: str = "http://localhost:11434"):
        """
        Args:
            model_name: KullanÄ±lacak Ollama modeli
            base_url: Ollama API URL'i
        """
        self.model_name = model_name
        self.base_url = base_url
        self.api_url = f"{base_url}/api/generate"
        
    def _call_ollama(self, prompt: str, max_tokens: int = 1000) -> str:
        """Ollama API'ye istek gÃ¶nder"""
        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "num_predict": max_tokens,
                    "temperature": 0.7
                }
            }
            
            response = requests.post(self.api_url, json=payload, timeout=120)
            response.raise_for_status()
            
            result = response.json()
            return result.get("response", "")
            
        except requests.exceptions.ConnectionError:
            raise ConnectionError(
                f"Ollama'ya baÄŸlanÄ±lamadÄ±! LÃ¼tfen Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.\n"
                f"BaÅŸlatmak iÃ§in: ollama serve\n"
                f"Model indirmek iÃ§in: ollama pull {self.model_name}"
            )
        except Exception as e:
            raise Exception(f"Ollama API hatasÄ±: {e}")
    
    def summarize_comments(
        self, 
        comments: List[str], 
        video_title: str = "",
        sentiment_distribution: Optional[dict] = None
    ) -> OllamaSummaryResult:
        """
        YorumlarÄ± Ã¶zetle
        
        Args:
            comments: Yorum metinleri listesi
            video_title: Video baÅŸlÄ±ÄŸÄ± (opsiyonel)
            sentiment_distribution: Sentiment analizi sonuÃ§larÄ± (opsiyonel)
                Ã–rnek: {"positive": 26, "negative": 74, "neutral": 0}
            
        Returns:
            OllamaSummaryResult objesi
        """
        if not comments:
            return OllamaSummaryResult(
                summary="Analiz edilecek yorum bulunamadÄ±.",
                raw_response=""
            )
        
        # Ä°lk 100 yorumu al (Ollama iÃ§in)
        comments_sample = comments[:100]
        comments_text = "\n".join([f"- {c[:300]}" for c in comments_sample])
        
        # Sentiment bilgisini prompt'a ekle
        sentiment_context = ""
        if sentiment_distribution:
            pos = sentiment_distribution.get('positive', 0)
            neg = sentiment_distribution.get('negative', 0)
            neu = sentiment_distribution.get('neutral', 0)
            
            # Dominant sentiment'i belirle
            if neg > pos and neg > neu:
                dominant = f"Ã‡OÄUNLUKLA NEGATÄ°F (Negatif: %{neg}, Pozitif: %{pos}, NÃ¶tr: %{neu})"
            elif pos > neg and pos > neu:
                dominant = f"Ã‡OÄUNLUKLA POZÄ°TÄ°F (Pozitif: %{pos}, Negatif: %{neg}, NÃ¶tr: %{neu})"
            else:
                dominant = f"KARIÅIK (Pozitif: %{pos}, Negatif: %{neg}, NÃ¶tr: %{neu})"
            
            sentiment_context = f"\nâš ï¸ SENTIMENT ANALÄ°Z SONUCU: {dominant}\n"
        
        prompt = f"""Sen bir YouTube video analiz uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki yorumlarÄ± analiz et ve TÃ¼rkÃ§e Ã¶zet Ã§Ä±kar.

{"Video: " + video_title if video_title else ""}
{sentiment_context}
YORUMLAR:
{comments_text}

GÃ–REV: Bu yorumlarÄ± analiz ederek aÅŸaÄŸÄ±daki bilgileri ver:

1. GENEL Ã–ZET (2-3 cÃ¼mle): Ä°zleyicilerin genel tepkisi nedir? (Sentiment analizi sonucuna dikkat et!)

2. ANA NOKTALAR (3-5 madde): En Ã§ok vurgulanan konular

3. DUYGU ANALÄ°ZÄ°: Genel atmosfer - YukarÄ±daki sentiment daÄŸÄ±lÄ±mÄ±nÄ± doÄŸrula

4. Ã–NERÄ°LER (2-3 madde): Ä°Ã§erik Ã¼reticiye Ã¶neriler

KÄ±sa ve Ã¶z yanÄ±t ver. Sentiment analizi sonucuyla uyumlu bir Ã¶zet yaz!"""

        try:
            response_text = self._call_ollama(prompt, max_tokens=800)
            
            return OllamaSummaryResult(
                summary=response_text,
                raw_response=response_text
            )
            
        except Exception as e:
            print(f"âŒ Ollama Ã¶zet hatasÄ±: {e}")
            return OllamaSummaryResult(
                summary=f"Hata: {str(e)}",
                raw_response=""
            )
    
    def check_connection(self) -> bool:
        """Ollama baÄŸlantÄ±sÄ±nÄ± kontrol et"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def list_models(self) -> List[str]:
        """Mevcut modelleri listele"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                return [model["name"] for model in data.get("models", [])]
            return []
        except:
            return []

    def summarize_video_description(self, description: str) -> str:
        """Video aÃ§Ä±klamasÄ±nÄ± Ã¶zetle ve iÃ§eriÄŸi Ã§Ä±kar"""
        if not description:
            return "Video aÃ§Ä±klamasÄ± bulunamadÄ±."
        
        prompt = f"""AÅŸaÄŸÄ±daki YouTube video aÃ§Ä±klamasÄ±nÄ± analiz et ve videonun konusunu akÄ±cÄ± bir dille Ã¶zetle.
        
        AÃ‡IKLAMA:
        {description[:2500]}
        
        GÃ–REV:
        Bu videonun ne hakkÄ±nda olduÄŸunu 3-4 cÃ¼mleyi geÃ§meyecek ÅŸekilde, tek bir paragraf halinde Ã¶zetle.
        
        KURALLAR:
        - Kesinlikle madde iÅŸareti (bullet point) kullanma.
        - Listeleme yapma.
        - AkÄ±cÄ± bir TÃ¼rkÃ§e kullan.
        - Sadece Ã¶zeti yaz, "Ä°ÅŸte Ã¶zet:" gibi baÅŸlangÄ±Ã§lar yapma.
        """
        
        try:
            return self._call_ollama(prompt, max_tokens=300)
        except Exception as e:
            return f"Ã–zetlenemedi: {e}"


# Test
if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ¤– OLLAMA LLM TEST")
    print("=" * 60)
    
    ollama = OllamaLLM(model_name="gemma3:4b")
    
    # BaÄŸlantÄ± kontrolÃ¼
    if ollama.check_connection():
        print("âœ… Ollama baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!")
        
        models = ollama.list_models()
        print(f"\nğŸ“‹ Mevcut modeller: {', '.join(models)}")
        
        # Test yorumlarÄ±
        test_comments = [
            "Bu video harika olmuÅŸ, Ã§ok beÄŸendim!",
            "AÃ§Ä±klamalar net ve anlaÅŸÄ±lÄ±r",
            "Devam videolarÄ± bekliyoruz",
            "Ses kalitesi biraz dÃ¼ÅŸÃ¼k olmuÅŸ",
            "10 numara iÃ§erik!"
        ]
        
        print("\nğŸ“ Test Ã¶zetlemesi...")
        result = ollama.summarize_comments(test_comments, "Test Video")
        print(f"\n{result.summary}")
    else:
        print("âŒ Ollama'ya baÄŸlanÄ±lamadÄ±!")
        print("\nÃ‡Ã¶zÃ¼m:")
        print("  1. Ollama'yÄ± baÅŸlatÄ±n: ollama serve")
        print("  2. Model indirin: ollama pull gemma3:4b")
